# Lecture 2 --- Setting the Scene

## Background

- Microprocessors evolved over 50 years
- Key first developments 
	- First transistor in 1947
	- First integrated circuit in 1958
	- First microprocessor in 1972
- Since the first electronic computers were created in the late 1940s
	performance has increased at a dramatic rate due to,
	- Advances in circuit technology
	- Computer Architecture 
	- Compiling Techniques
	- Algorithm Development

> Moore's Law, exponential increase in transistor count on a chip

Moore's law has knock on effects on fields like DNA sequencing and camera pixel
density. Moore predicts his law will end by 2025 due to the physical limit on
the size of a transistor. Apple M1 ~16 billion transistors, Intel 4004 ~2300
transistors, 8 billion fold increase in 50 years.

### The Role of CA

Architectural innovation compliments technological innovation. That is it is
increasing with the years like Moore's Law.

## History of Computer Architecture

- Earliest computers -> simplest possible implementation
	- Think INF2D-CS
- Late 60's
	- Pipelining
	- Parallel execution
	- Hardware detects parallelism between instructions
- Scientific Computing
	- Driven by US military
	- Development of Vector processing (70s)
- Emergence of Microprocessors
	- Driven by commercial desktop use
	- Not initially a threat to mainframes
	- Eventually rendered mainframes obsolete
- Microprocessor (r)evolution (80s-)
	- Started simple, just like early computers
	- Re used concepts 
- "State of the art"
	- Huawei Kunpeng 920
	- Apple A15
	- Apple M2

## Does Moore's Law Guarantee Better Performance

No, clock speed does not increase at the same rate as Moore's Law. Power
consumption has also levelled like clock speed. This is due to heat.

## Power Wall/the end of "free" energy

Shrinking a transistor also shrinks the voltage needed to operate it. Given $p
= 1/2 c ^2 f$, if we decrease the voltage linearly we decrease the power
quadratically. Therefore, we can keep the power density constant between
generations. Power density is the important metric in cooling. This is called
Denard Scaling. This ended in the year 2000. There is a minimum voltage due to
interference.

Another way to decrease the power is lower the frequency, hence the clock speed
decrease. In modern processors we disable parts of the processor to reduce the
power density and keep it cool.

## The Great Moore's Law Contradiction (Software Bloat)

Windows 2000 on a 2000s machine is as fast as Windows 2007 on a 2007 machine.
In other words the demands of software increase with processing power.

## Power Limitations in a single CPU Throughput\

- Future generations can pack more on a chip
- Sustained performance of a single core limited by thermal power
- 3x performance gain over 7 generations expected
- 24x performance gain possible if thermals solved.

## Today: the era of multicore 

- Frequency of processors stopeed scaling ~2004
- Why?
	- Power wall/brealdown of Dennard scaling
- Parallel architectures
	- performance through parallelism
	- software must expose parallelism
	- computer architecture must expose this

## Today: the age of specialisation

Today we can solve the power problem by using specialised processors built into
a modern chip. Think GPU, Vision proc, TPU, Neural Engine etc. Unlikely to be
doing all at once so only turn on the correct chip, lowers power density. CPU's
will have hundreds of cores by 2034 (in theory) due to specialised chips.

## The Future: Mega Chips for AI?

- Startup Cerebras have 400k cores
- wafer scale integration
- 1.2 trillion transistors
- 18GB on chip memory
- 50x state of the art Nvidia GPU
- 16nm size
- 15Kw

## Current Trends

- Very complex processor designs
- Parallelism at chip level
- power concious
- specialisation
- open source architecture
- security: meltdown, spectre
